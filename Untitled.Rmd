---
title: "Untitled"
author: "none"
date: "12/6/2021"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(nnet)
library(ggpubr)
data("iris")
```

## Data summary
This data consist of 150 rows with 5 columns. Column summary are given below.

- Sepal.Length: Length of the sepal (in cm)
- Sepal.Width: Width of the sepal (in cm)
- Petal.Length: Length of the petal (in cm)
- Petal.Width: Width of the petal (in cm)
- Species: Species name
```{r}
iris %>% 
    summary()
```

\pagebreak
## Density plot of different variables
```{r}
iris %>% 
    pivot_longer(-Species) %>% 
    ggplot(aes(value, fill = Species)) +
    geom_density(alpha = .7) +
    facet_wrap(~name, scales = "free") +
    scale_y_continuous(labels = NULL) +
    labs(title = "Density plot withh respect to species")
```
So without the sepal width other 3 variables are very sensitive to the species class. 

\pagebreak
## Scatter plot of the Sepal and Petal lengh with respect to the Species
```{r}
ggarrange(
    iris %>%
        ggplot(aes(Sepal.Length, Sepal.Width, col = Species)) +
        geom_point() +
        labs(title = "Sepal",x = NULL, y = NULL),
    iris %>%
        ggplot(aes(Petal.Length, Petal.Width, col = Species)) +
        geom_point() +
        labs(title = "Petal",x = NULL, y = NULL), common.legend = T, legend = "bottom"
) 
```
So we can see that Petal length and Petal width can separate the species and Sepal length and sepal width can separate the species partially since the species "versicolor" and "verginica" are mixed up in that plot.

\pagebreak
## Scatter plot of the PCA with respect to the Species
```{r}
(iris %>% 
    select(-Species) %>% 
    princomp())$scores %>% 
    as.data.frame() %>% 
    select(1:2) %>% 
    bind_cols(Species = iris$Species) %>% 
    ggplot(aes(Comp.1, Comp.2, col = Species)) +
    geom_point() +
    labs(title = "Scatter plot of the PCA with respect to the Species")
```

## Correlation among the predictor variables
```{r}
cor(select(iris, -Species)) %>% 
corrplot::corrplot()
```
We can see a high correlation the explanatory variables. So this multi-collinearity may cause an performance drop of the model.

## Spliting the test and train set
```{r}
set.seed(1234)
iris_train <-
    iris %>%
    mutate(id = row_number(), .before = everything()) %>%
    group_by(Species) %>%
    slice_sample(n = 35)

iris_test <-
    iris %>%
    mutate(id = row_number(), .before = everything()) %>%
    anti_join(iris_train, by = "id") %>% 
    select(-id)

iris_train <- select(iris_train, -id)
```

\pagebreak
## Fitting model
```{r}
model <- multinom(formula = Species ~ ., data = iris_train)

table(predicted = predict(model, iris_test), true = iris_test$Species)
```
The accuracy of the multinomial logistic regression is (1 - 3/45) = 0.933 or 93%. Lets see whether the PCA can give us better performance or not

\pagebreak
## Fitting model with PCA
```{r}
model_pca <-
    (iris_train %>%
         ungroup() %>%
         select(-Species) %>%
         princomp())$score %>%
    as.data.frame() %>%
    bind_cols(Species = iris_train$Species) %>%
    multinom(formula = Species ~ .)


table(predicted = predict(model_pca,
        newdata = (iris_test %>%
                       ungroup() %>%
                       select(-Species) %>%
                       princomp())$score), true = iris_test$Species)
```
The accuracy of the multinomial PCA logistic regression is (1 - 3/45) = 0.933 or 93%. which is equal to the the previous model. So both of the model actually performing the same way.


So the conclusion is we don't have enough evidence that whether the PCA logistic regression perform well or not.



















